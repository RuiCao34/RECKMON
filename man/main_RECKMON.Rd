% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/main.R
\name{main_RECKMON}
\alias{main_RECKMON}
\title{Main function fitting RECKMON (REluCtant Kernel-based Modeling On Non-linearity)}
\usage{
main_RECKMON(
  x,
  y,
  poly_features = min(ncol(x), floor(nrow(x)/log(ncol(x)))),
  step_gaussian = 1,
  guassian_para_list = NULL,
  cv = 5,
  non_interactions = NULL,
  interactions = NULL,
  lambda = 0.001,
  mc.cores = 1
)
}
\arguments{
\item{x}{A numeric matrix of predictors. Each row is an observation and
each column is a feature.}

\item{y}{A numeric vector of the response variable.}

\item{poly_features}{The number of top-ranked interaction features to select
in the second step. Defaults to $n/log(p)$}

\item{step_gaussian}{The number of Gaussian kernel features to add at each
step during the final stepwise selection. Defaults to `1`.}

\item{guassian_para_list}{A numeric vector of candidate values for the
Gaussian kernel hyperparameter (`gamma`). If not provided, a default value
is calculated based on the median distance between data points.}

\item{cv}{The number of folds for the internal cross-validation used to
tune the Gaussian hyperparameter. Defaults to `5`.}

\item{non_interactions}{An optional integer vector of feature indices to
exclude from the interaction screening in Stage 2.}

\item{interactions}{An optional integer vector of feature indices to force
into the interaction screening in Stage 2.}

\item{lambda}{A small numeric value for the regularization parameter used
when inverting the kernel matrix. Defaults to `1e-3`.}

\item{mc.cores}{The number of CPU cores to use for parallelizing the internal
cross-validation. Defaults to `1`.}
}
\value{
A list object containing the results of the
  modeling process:
  \item{BIC}{The final BIC value of the selected Gaussian model.}
  \item{poly_feature}{A vector of indices for the selected interaction features.}
  \item{gaussian_feature}{A vector of indices for the selected Gaussian kernel features.}
  \item{lasso_fit1}{The fitted `glmnet` object from the first stage.}
  \item{lasso_fit2}{The fitted `glmnet` object from the second stage.}
  \item{theta_hat}{The estimated variance components (`sigma_e^2`, `sigma_g^2`) from the final Gaussian model.}
  \item{guassian_para}{The best value selected for the Gaussian kernel hyperparameter.}
  \item{r2}{The final residuals after the first two stages, used as input for the third stage.}
}
\description{
Implements a three-stage modeling process to capture linear, interaction, and non-linear (Gaussian kernel) effects in the data.
}
\details{
The function follows a structured, sequential approach:

1.  **Main Effects**: A LASSO regression is first fit on the
    response variable `y` against the predictors `x` to model the primary
    linear effects. The residuals from this stage are passed to the next.

2.  **Interaction Effects**: The function screens for important interaction
    terms by fitting a polynomial kernel and then uses LASSO again to model
    the residuals from the first stage. This captures key second-order effects.

3.  **Non-linear Effects**: The remaining residuals are modeled using a
    Gaussian kernel regression. The Gaussian kernel's
    hyperparameter is tuned automatically using
    k-fold cross-validation. This internal CV process is parallelized for
    efficiency, assigning each fold-parameter combination to a separate core.
    The best parameter is then used to fit the final stepwise Gaussian model
    based on an information criterion (BIC).
}
